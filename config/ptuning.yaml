path:
  train_path: ./dataset/train/train.csv
  dev_path: ./dataset/dev/dev.csv
  test_path: ./dataset/test/test.csv
  predict_path: ./dataset/predict/predict.csv
  pretrain_path : "./dataset/pretrain/all_data.csv"

  # TAPT를 진행한 모델을 불러오려면 디렉토리 경로를 입력해주세요.
  load_pretrained_model_path : /opt/ml/level2_klue(dev-1123)/klue-roberta-pretrained
  # inference를 하는 경우 로드할 모델의 경로를 입력해주세요.
  load_model_path: /opt/ml/level2_klue(dev-1123)/step_saved_model/klue-roberta-large/23-14-46/pytorch_model.bin

model:
  model_class_name: TAPT #model.py에서 사용할 모델 이름
  model_name: KoGPT2/PTUNE

data:
  tem: 0 
  # defalut(0)  concat 
  # 1           Typed entity marker
  # 2           Typed entity marker + emask (RBERT에서 사용)

train:
  max_epoch: 100
  batch_size: 64
  learning_rate: 5e-4
  loss: focal # loss.py 맨 아래 config 되어 있는 값을 받아서 loss 함수를 가져옵니다.
  save_steps: 4000
  # save_steps은 반드시 eval_steps의 배수여야 합니다!!!! """n * save_steps = eval_steps"""
  eval_steps: 2000
  logging_steps: 1500
  dropout: 0.2
  rdrop: False # batch_size 
  
utils: 
  seed: 42
  monitor: micro f1 score
  patience: 20
  top_k: 3